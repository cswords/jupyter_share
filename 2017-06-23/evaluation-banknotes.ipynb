{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import wget\n",
    "\n",
    "# Define how to get data\n",
    "def get_iris(storage_folder=\"temp\", data_file=\"iris_data.txt\", splitter=','):\n",
    "    data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):        \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def get_satellite(storage_folder=\"temp\", data_file=\"satellite_data.txt\", splitter=' '):\n",
    "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn'\n",
    "    # data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):           \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def get_banknote(storage_folder=\"temp\", data_file=\"banknote_data.txt\", splitter=','):\n",
    "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):           \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "vector_values, labels = get_banknote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      "{'0', '1'}\n",
      "Sample size: \n",
      "1372\n",
      "time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "num_clusters = len(set(labels))\n",
    "num_vectors = len(vector_values)\n",
    "\n",
    "print(\"Labels: \")\n",
    "print(set(labels))\n",
    "print(\"Sample size: \")\n",
    "print(num_vectors)\n",
    "\n",
    "vectors = tf.constant(vector_values, dtype = tf.half)\n",
    "\n",
    "npArray = np.array(vector_values)\n",
    "mlab_pca = mlabPCA(npArray)\n",
    "users_2d = mlab_pca.project(npArray, minfrac=mlab_pca.fracs[1])\n",
    "\n",
    "def drawClusters(assignment_values):\n",
    "    data = {\"x\": [], \"y\": [], \"cluster\": []}\n",
    "    for i in range(len(assignment_values)):\n",
    "        data[\"x\"].append(users_2d[i][0])\n",
    "        data[\"y\"].append(users_2d[i][1])\n",
    "        data[\"cluster\"].append(assignment_values[i])\n",
    "    df = pd.DataFrame(data)\n",
    "    sns.lmplot(\"x\", \"y\", data=df, \n",
    "               fit_reg=False, size=7, \n",
    "               hue=\"cluster\", legend=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "def atan2(x, y, epsilon=1.0e-12):\n",
    "    \"\"\"\n",
    "    A hack until the tf developers implement a function that can find the angle from an x and y co-ordinate.\n",
    "    :param x: \n",
    "    :param epsilon: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # Add a small number to all zeros, to avoid division by zero:\n",
    "    x = tf.where(tf.equal(x, 0.0), x+epsilon, x)\n",
    "    y = tf.where(tf.equal(y, 0.0), y+epsilon, y)\n",
    "\n",
    "    angle = tf.where(tf.greater(x,0.0), tf.atan(y/x), tf.zeros_like(x))\n",
    "    angle = tf.where(tf.logical_and(tf.less(x,0.0),  tf.greater_equal(y,0.0)), tf.atan(y/x) + np.pi, angle)\n",
    "    angle = tf.where(tf.logical_and(tf.less(x,0.0),  tf.less(y,0.0)), tf.atan(y/x) - np.pi, angle)\n",
    "    angle = tf.where(tf.logical_and(tf.equal(x,0.0), tf.greater(y,0.0)), 0.5*np.pi * tf.ones_like(x), angle)\n",
    "    angle = tf.where(tf.logical_and(tf.equal(x,0.0), tf.less(y,0.0)), -0.5*np.pi * tf.ones_like(x), angle)\n",
    "    angle = tf.where(tf.logical_and(tf.equal(x,0.0), tf.equal(y,0.0)), tf.zeros_like(x), angle)\n",
    "    return angle\n",
    "    \n",
    "vectors_2d = tf.subtract(users_2d, tf.reduce_mean(users_2d, 0))\n",
    "angles_2d = tf.add(atan2(vectors_2d[:,1], vectors_2d[:,0]), np.pi)\n",
    "\n",
    "seg = np.pi*2/num_clusters\n",
    "init_assignments = tf.cast(tf.divide(angles_2d, seg), dtype=tf.int64)\n",
    "\n",
    "def initialize_clusters():\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        assignment_values = sess.run(init_assignments)\n",
    "        sess.close()\n",
    "    return assignment_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 713 ms\n"
     ]
    }
   ],
   "source": [
    "#iteration variable\n",
    "assignments = tf.Variable(initialize_clusters(), dtype=tf.int64)\n",
    "\n",
    "#clusters are based on assignments\n",
    "clusters = [tf.gather(vectors, tf.squeeze(tf.where(tf.equal(assignments, c)), squeeze_dims=[1])) for c in range(num_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "def crossDistance(a, b, ord='euclidean'):\n",
    "    diff = tf.subtract(tf.expand_dims(a, 0), tf.expand_dims(b, 1))\n",
    "    result = tf.norm(diff, ord, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20 ms\n",
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "means = tf.concat([\n",
    "    tf.expand_dims(tf.reduce_mean(cluster, 0), 0) \n",
    "    for cluster in clusters], 0)\n",
    "kmeans = tf.argmin(crossDistance(vectors, means), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57 ms\n",
      "time: 60.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "medoids = tf.concat([\n",
    "    tf.expand_dims(tf.gather(cluster, tf.argmin(tf.reduce_sum(crossDistance(cluster, cluster), 0), 0)), 0)\n",
    "    for cluster in clusters], 0)\n",
    "kmedoids = tf.argmin(crossDistance(vectors, medoids), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 831 ms\n",
      "time: 959 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def subsample(D, size, t):\n",
    "    size_D = tf.shape(D)[0]\n",
    "    selector_1 = tf.range(size_D, dtype=tf.int32)\n",
    "    selector_t = tf.slice(tf.map_fn(\n",
    "      lambda one: tf.random_shuffle(selector_1)  \n",
    "    , tf.ones([t, size_D], dtype=tf.int32)), [0,0], [t, size])\n",
    "    \n",
    "    return tf.gather(D, selector_t)\n",
    "\n",
    "def HM(X, D, t=500, psi = 20, lmbda=1.0, dt=tf.half):\n",
    "    size_X = tf.shape(X)[0]\n",
    "    dims_X = tf.shape(X)[1]\n",
    "    size_D = tf.shape(D)[0]\n",
    "    \n",
    "    ones_tX = tf.ones([t, size_X, dims_X], dtype=dt)  \n",
    "    \n",
    "    psi = tf.cond(tf.logical_and(tf.less(0, psi), tf.less(psi, size_D)), lambda: tf.constant(psi), lambda: size_D)\n",
    "    set_t_psi = tf.cond(psi<size_D, \n",
    "                        lambda: subsample(D, psi, t), \n",
    "                        # order of D will not matter and it will be broadcasted\n",
    "                        lambda: tf.expand_dims(D, 0)) \n",
    "    \n",
    "    ones_t_psi = tf.ones([t, psi, dims_X], dtype=dt) \n",
    "    \n",
    "    hm_X = tf.zeros([size_X], dtype=dt)\n",
    "    \n",
    "    directions = tf.random_uniform([t, dims_X], minval = -1, maxval = 1, dtype = dt)\n",
    "    projectors = tf.divide(directions, tf.norm(directions, axis=1, keep_dims=True))\n",
    "    \n",
    "    projects_X = tf.squeeze(tf.matmul(\n",
    "        tf.expand_dims(tf.multiply(ones_tX, tf.expand_dims(X, 0)), 2), \n",
    "        tf.expand_dims(tf.multiply(ones_tX, tf.expand_dims(projectors, 1)), 3)), [2, 3])\n",
    "    \n",
    "    projects_psi = tf.squeeze(tf.matmul(\n",
    "        tf.expand_dims(tf.multiply(ones_t_psi, set_t_psi), 2), \n",
    "        tf.expand_dims(tf.multiply(ones_t_psi, tf.expand_dims(projectors, 1)), 3)), [2, 3])\n",
    "    \n",
    "    mid_t_min = tf.add(\n",
    "        tf.multiply(tf.reduce_max(projects_psi, 1), (1-lmbda)/2),\n",
    "        tf.multiply(tf.reduce_min(projects_psi, 1), (1+lmbda)/2))\n",
    "    \n",
    "    mid_t_max = tf.add(\n",
    "        tf.multiply(tf.reduce_max(projects_psi, 1), (1+lmbda)/2),\n",
    "        tf.multiply(tf.reduce_min(projects_psi, 1), (1-lmbda)/2))\n",
    "    \n",
    "    mid_t = tf.add(mid_t_min, tf.multiply(tf.random_uniform([t], 0, 1, dtype=dt), tf.subtract(mid_t_max, mid_t_min)))\n",
    "    \n",
    "    mass_l_t = tf.divide(tf.reduce_sum(\n",
    "        tf.where(\n",
    "            tf.less(projects_psi, tf.expand_dims(mid_t, 1)), \n",
    "            tf.ones([t, psi], dtype=dt), \n",
    "            tf.zeros([t, psi], dtype=dt)), 1), tf.cast(psi, dtype=dt))\n",
    "    \n",
    "    mass_r_t = tf.add(tf.multiply(mass_l_t, -1), 1)\n",
    "    \n",
    "    mass_t = tf.where(tf.less(projects_X, tf.expand_dims(mid_t, 1)), \n",
    "                      tf.multiply(tf.ones([t, size_X], dtype=dt), tf.expand_dims(mass_l_t, 1)), \n",
    "                      tf.multiply(tf.ones([t, size_X], dtype=dt), tf.expand_dims(mass_r_t, 1)))\n",
    "    hs_mass = tf.reduce_mean(mass_t, 0)\n",
    "    return hs_mass\n",
    "\n",
    "kmass = tf.argmax(tf.concat([\n",
    "    tf.expand_dims(tf.divide(HM(vectors, cluster), tf.reduce_min(HM(vectors, cluster), 0, keep_dims=True)), 1)\n",
    "    for cluster in clusters\n",
    "], 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28 ms\n",
      "time: 89 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "# method = kmeans\n",
    "# method = kmedoids\n",
    "# method = kmass\n",
    "\n",
    "def run(method = kmeans, p=1, round_max=10, output=False):\n",
    "    assignment_values = initialize_clusters()\n",
    "    \n",
    "    # os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "    # tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    sess_config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    round_i = 0\n",
    "    keep_hurdle = num_vectors * p\n",
    "    keep_max = -1\n",
    "    best_result = assignment_values\n",
    "\n",
    "    # drawClusters(assignment_values)\n",
    "    while round_i < round_max:    \n",
    "        round_i = round_i + 1\n",
    "        if output:\n",
    "            print(round_i)\n",
    "        with tf.Session(config=sess_config) as sess:\n",
    "            sess.run(init_op)\n",
    "            round_result = sess.run(method)\n",
    "\n",
    "            keep_count = np.sum([\n",
    "                1 if assignment_values[i]==round_result[i] else 0\n",
    "                for i in range(num_vectors)\n",
    "            ])\n",
    "            if output:\n",
    "                print(keep_count)\n",
    "            if keep_max < keep_count:\n",
    "                keep_max = keep_count\n",
    "                best_result = round_result\n",
    "                if output:\n",
    "                    print(\"best_result was updated.\")\n",
    "\n",
    "            assignment_values = sess.run(tf.assign(assignments, round_result))\n",
    "    #         drawClusters(assignment_values)\n",
    "            sess.close()\n",
    "        if keep_count >= keep_hurdle:\n",
    "            if output:\n",
    "                print(\"keep_hurdle was hit.\")\n",
    "            break\n",
    "\n",
    "    if output:\n",
    "        print(\"The final P is \")\n",
    "        print(float(keep_max)/float(num_vectors))    \n",
    "        drawClusters(best_result)\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 75.1 ms\n"
     ]
    }
   ],
   "source": [
    "%run metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "n_runs = 40 # number of runs with random initialization for clustering evaluation.\n",
    "\n",
    "def evaluation_scores(groundtruth, labels_pred):\n",
    "    \"\"\"\n",
    "    Eval scores of the predicted results.\n",
    "     \n",
    "    :param: groundtruth (type list): the groundtruth (GT) of cluster assignment. Each element denotes an item's GT cluster_id. \n",
    "    :param: labels_pred (type list): the predicted cluster assignments. Each element denotes an item's predicted cluster_id.\n",
    "    \"\"\"\n",
    "    NMI = normalized_mutual_info_score(groundtruth,labels_pred)\n",
    "    A = accuracy(groundtruth,labels_pred)\n",
    "    F1 = f_measure(groundtruth,labels_pred)\n",
    "    P = purity(groundtruth,labels_pred)\n",
    "    RI = random_index(groundtruth,labels_pred)\n",
    "    ARI = adjusted_rand_score(groundtruth,labels_pred)\n",
    "    map_pairs = get_map_pairs(groundtruth,labels_pred)\n",
    "    return NMI, A, F1, P, RI, ARI, map_pairs\n",
    "    \n",
    "def evaluation(method = kmeans):    \n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    NMIs,As,F1s = [],[],[]\n",
    "    i_run = 1\n",
    "    labels_unique = np.unique(labels)\n",
    "    labels_indexed = []\n",
    "    for label in labels:\n",
    "        labels_indexed.append(np.where(labels_unique==label))\n",
    "    labels_indexed = np.squeeze(labels_indexed)\n",
    "    while i_run <= n_runs:\n",
    "        t1 = time.time()\n",
    "        result = run(method = method, output=False)\n",
    "        NMI,A,F1,P,RI,ARI,map_pairs = evaluation_scores(labels_indexed, result)\n",
    "        print(\"\\t {}-th run(time={}s),<Acc, F1, NMI>\\t{}\\t{}\\t{}\".format(i_run, time.time()-t1, A, F1, NMI))\n",
    "        i_run = i_run+1\n",
    "        NMIs.append(NMI)\n",
    "        As.append(A)\n",
    "        F1s.append(F1)\n",
    "\n",
    "    print(\"Results of {} runs (mean,std_var):\\n\\t Acc: {}, {}, {}, {}\\n\\t F1 : {}, {}, {}, {}\\n\\t NMI: {}, {}, {}, {}\"\n",
    "          .format(n_runs\n",
    "                  , np.mean(As),np.std(As), np.min(As), np.max(As)\n",
    "                  , np.mean(F1s),np.std(F1s), np.min(F1s), np.max(F1s)\n",
    "                  ,np.mean(NMIs),np.std(NMIs), np.min(NMIs), np.max(NMIs)))\n",
    "    print(\"Running time: {}s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1-th run(time=14.523083209991455s),<Acc, F1, NMI>\t0.6253644314868805\t0.6085935279864814\t0.12179877134921835\n",
      "\t 2-th run(time=10.657576560974121s),<Acc, F1, NMI>\t0.5889212827988338\t0.579627633678692\t0.04858947794069001\n",
      "\t 3-th run(time=10.569509983062744s),<Acc, F1, NMI>\t0.5860058309037901\t0.5440921812509906\t0.17464870582635483\n",
      "\t 4-th run(time=10.633932828903198s),<Acc, F1, NMI>\t0.6319241982507289\t0.6145859466174809\t0.13877133666993777\n",
      "\t 5-th run(time=10.634576797485352s),<Acc, F1, NMI>\t0.6173469387755102\t0.5933942799683125\t0.14263643979276286\n",
      "\t 6-th run(time=10.82769250869751s),<Acc, F1, NMI>\t0.6537900874635568\t0.651253949944225\t0.0990416362671421\n",
      "\t 7-th run(time=10.845707416534424s),<Acc, F1, NMI>\t0.5998542274052479\t0.5652652204863982\t0.16343635976190968\n",
      "\t 8-th run(time=10.98724627494812s),<Acc, F1, NMI>\t0.6275510204081632\t0.6065469626393891\t0.1509549965706151\n",
      "\t 9-th run(time=11.08396601676941s),<Acc, F1, NMI>\t0.6355685131195336\t0.619730551929504\t0.13811690265825577\n",
      "\t 10-th run(time=11.106891870498657s),<Acc, F1, NMI>\t0.6268221574344023\t0.6242278221487523\t0.06853628047815816\n",
      "\t 11-th run(time=11.182950258255005s),<Acc, F1, NMI>\t0.6166180758017493\t0.589604658564588\t0.16201817260158782\n",
      "\t 12-th run(time=11.258052825927734s),<Acc, F1, NMI>\t0.6173469387755102\t0.5924667164135966\t0.14864694530995076\n",
      "\t 13-th run(time=11.348279237747192s),<Acc, F1, NMI>\t0.6530612244897959\t0.636600783471384\t0.18775287593119402\n",
      "\t 14-th run(time=11.404306650161743s),<Acc, F1, NMI>\t0.6202623906705539\t0.591679495487456\t0.19221170228875697\n",
      "\t 15-th run(time=11.381104707717896s),<Acc, F1, NMI>\t0.5670553935860059\t0.5620966025909289\t0.011232065431208148\n",
      "\t 16-th run(time=11.603261947631836s),<Acc, F1, NMI>\t0.642128279883382\t0.619726840884375\t0.21509736520057196\n",
      "\t 17-th run(time=11.63927149772644s),<Acc, F1, NMI>\t0.6115160349854227\t0.5790546176242035\t0.2002072288016126\n",
      "\t 18-th run(time=11.811410903930664s),<Acc, F1, NMI>\t0.6020408163265306\t0.5962722475118332\t0.05353533880024407\n",
      "\t 19-th run(time=11.822434902191162s),<Acc, F1, NMI>\t0.5532069970845481\t0.4963443108770047\t0.142288980179213\n",
      "\t 20-th run(time=11.84960651397705s),<Acc, F1, NMI>\t0.5349854227405247\t0.34852801519237275\t0.046525134958967804\n",
      "\t 21-th run(time=11.990745782852173s),<Acc, F1, NMI>\t0.575801749271137\t0.5735361976980425\t0.01608600107175086\n",
      "\t 22-th run(time=12.400585889816284s),<Acc, F1, NMI>\t0.6107871720116618\t0.6058209427348976\t0.05995855661830675\n",
      "\t 23-th run(time=12.221226692199707s),<Acc, F1, NMI>\t0.619533527696793\t0.6189432328673942\t0.05336086516155903\n",
      "\t 24-th run(time=12.387863159179688s),<Acc, F1, NMI>\t0.5969387755102041\t0.5899592670068821\t0.05145799091124327\n",
      "\t 25-th run(time=12.376097440719604s),<Acc, F1, NMI>\t0.6137026239067055\t0.5841064087241825\t0.17399020071660865\n",
      "\t 26-th run(time=12.55990743637085s),<Acc, F1, NMI>\t0.6290087463556852\t0.6289517797936239\t0.053967662936704824\n",
      "\t 27-th run(time=12.474002361297607s),<Acc, F1, NMI>\t0.6224489795918368\t0.6208173361085747\t0.060556642405197134\n",
      "\t 28-th run(time=12.693934202194214s),<Acc, F1, NMI>\t0.5408163265306123\t0.48923587474097535\t0.0688075303016672\n",
      "\t 29-th run(time=12.800095081329346s),<Acc, F1, NMI>\t0.641399416909621\t0.6351190064299586\t0.10085322464449066\n",
      "\t 30-th run(time=12.899165391921997s),<Acc, F1, NMI>\t0.6180758017492711\t0.5894983269911964\t0.18201827981440907\n",
      "\t 31-th run(time=12.95322036743164s),<Acc, F1, NMI>\t0.6282798833819242\t0.6193624053690807\t0.09329177618510724\n",
      "\t 32-th run(time=13.063179016113281s),<Acc, F1, NMI>\t0.6290087463556852\t0.6020661733868826\t0.2181222816953034\n",
      "\t 33-th run(time=13.083771228790283s),<Acc, F1, NMI>\t0.5604956268221575\t0.5113772539930639\t0.11441701084747989\n",
      "\t 34-th run(time=13.149348735809326s),<Acc, F1, NMI>\t0.6370262390670554\t0.6155885424125354\t0.1830861605878087\n",
      "\t 35-th run(time=13.251861572265625s),<Acc, F1, NMI>\t0.5335276967930029\t0.47616968169404084\t0.06847546344444917\n",
      "\t 36-th run(time=13.24125051498413s),<Acc, F1, NMI>\t0.6268221574344023\t0.6080839819994834\t0.1352235774519981\n",
      "\t 37-th run(time=13.503660678863525s),<Acc, F1, NMI>\t0.6545189504373178\t0.6401675862619687\t0.17320232558057136\n",
      "\t 38-th run(time=13.524609804153442s),<Acc, F1, NMI>\t0.6530612244897959\t0.633102320016552\t0.2313576314208989\n",
      "\t 39-th run(time=13.671733140945435s),<Acc, F1, NMI>\t0.577259475218659\t0.5316854990545836\t0.16599140126821313\n",
      "\t 40-th run(time=13.574753284454346s),<Acc, F1, NMI>\t0.6056851311953353\t0.6054283555992711\t0.040668414768358314\n",
      "Results of 40 runs (mean,std_var):\n",
      "\t Acc: 0.6096392128279883, 0.03226315370024789, 0.5335276967930029, 0.6545189504373178\n",
      "\t F1 : 0.584967813453779, 0.055930988907027045, 0.34852801519237275, 0.651253949944225\n",
      "\t NMI: 0.12127349286626192, 0.060667941622968326, 0.011232065431208148, 0.2313576314208989\n",
      "Running time: 484.9948763847351s\n",
      "time: 8min 4s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmass)\n",
    "n_runs = 1 # no need to run kmeans and kmedoids for many times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1-th run(time=1.8286340236663818s),<Acc, F1, NMI>\t0.5940233236151603\t0.5886367000625554\t0.022950338330628962\n",
      "Results of 1 runs (mean,std_var):\n",
      "\t Acc: 0.5940233236151603, 0.0, 0.5940233236151603, 0.5940233236151603\n",
      "\t F1 : 0.5886367000625554, 0.0, 0.5886367000625554, 0.5886367000625554\n",
      "\t NMI: 0.022950338330628962, 0.0, 0.022950338330628962, 0.022950338330628962\n",
      "Running time: 1.8326191902160645s\n",
      "time: 1.83 s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1-th run(time=1.7407541275024414s),<Acc, F1, NMI>\t0.6049562682215743\t0.6023060796595746\t0.030854710768340055\n",
      "Results of 1 runs (mean,std_var):\n",
      "\t Acc: 0.6049562682215743, 0.0, 0.6049562682215743, 0.6049562682215743\n",
      "\t F1 : 0.6023060796595746, 0.0, 0.6023060796595746, 0.6023060796595746\n",
      "\t NMI: 0.030854710768340055, 0.0, 0.030854710768340055, 0.030854710768340055\n",
      "Running time: 1.7447750568389893s\n",
      "time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmedoids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
