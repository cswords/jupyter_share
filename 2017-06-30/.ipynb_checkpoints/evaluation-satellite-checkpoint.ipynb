{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autotime\n",
    "\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import wget\n",
    "\n",
    "# Define how to get data\n",
    "def get_iris(storage_folder=\"temp\", data_file=\"iris_data.txt\", splitter=','):\n",
    "    data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):        \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def get_satellite(storage_folder=\"temp\", data_file=\"satellite_data.txt\", splitter=' '):\n",
    "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn'\n",
    "    # data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):           \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def get_banknote(storage_folder=\"temp\", data_file=\"banknote_data.txt\", splitter=','):\n",
    "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):           \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "vector_values, labels = get_satellite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      "{'5', '4', '2', '3', '1', '7'}\n",
      "Sample size: \n",
      "4435\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "num_clusters = len(set(labels))\n",
    "num_vectors = len(vector_values)\n",
    "\n",
    "print(\"Labels: \")\n",
    "print(set(labels))\n",
    "print(\"Sample size: \")\n",
    "print(num_vectors)\n",
    "\n",
    "vectors = tf.constant(vector_values, dtype = tf.half)\n",
    "\n",
    "npArray = np.array(vector_values)\n",
    "mlab_pca = mlabPCA(npArray)\n",
    "users_2d = mlab_pca.project(npArray, minfrac=mlab_pca.fracs[1])\n",
    "\n",
    "def drawClusters(assignment_values):\n",
    "    data = {\"x\": [], \"y\": [], \"cluster\": []}\n",
    "    for i in range(len(assignment_values)):\n",
    "        data[\"x\"].append(users_2d[i][0])\n",
    "        data[\"y\"].append(users_2d[i][1])\n",
    "        data[\"cluster\"].append(assignment_values[i])\n",
    "    df = pd.DataFrame(data)\n",
    "    sns.lmplot(\"x\", \"y\", data=df, \n",
    "               fit_reg=False, size=7, \n",
    "               hue=\"cluster\", legend=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_clusters():\n",
    "    X = vector_values\n",
    "    n = np.shape(X)[0]\n",
    "    d = np.shape(X)[1]\n",
    "    K = num_clusters\n",
    "    S = np.ones(K)*(int(n/K))\n",
    "    S[K-1] = S[K-1] + n%K\n",
    "    \n",
    "    Y = np.zeros([n, 1])\n",
    "    for i in range(K):\n",
    "        yis0 = np.where(Y==0)[0]\n",
    "        a = np.take(X, yis0, axis=0)\n",
    "        b = np.random.randn(d, 1)\n",
    "        xt = np.squeeze(np.dot(a, b))\n",
    "        inx = np.argsort(xt)\n",
    "        Y[yis0[inx[range(int(S[i]))]]]=i\n",
    "    return np.squeeze(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iteration variable\n",
    "assignments = tf.Variable(initialize_clusters(), dtype=tf.int64)\n",
    "\n",
    "#clusters are based on assignments\n",
    "clusters = [tf.gather(vectors, tf.squeeze(tf.where(tf.equal(assignments, c)), squeeze_dims=[1])) for c in range(num_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crossDistance(a, b, ord='euclidean'):\n",
    "    diff = tf.subtract(tf.expand_dims(a, 0), tf.expand_dims(b, 1))\n",
    "    result = tf.norm(diff, ord, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "means = tf.concat([\n",
    "    tf.expand_dims(tf.reduce_mean(cluster, 0), 0) \n",
    "    for cluster in clusters], 0)\n",
    "kmeans = tf.argmin(crossDistance(vectors, means), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "medoids = tf.concat([\n",
    "    tf.expand_dims(tf.gather(cluster, tf.argmin(tf.reduce_sum(crossDistance(cluster, cluster), 0), 0)), 0)\n",
    "    for cluster in clusters], 0)\n",
    "kmedoids = tf.argmin(crossDistance(vectors, medoids), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def subsample(D, size, t):\n",
    "    size_D = tf.shape(D)[0]\n",
    "    selector_1 = tf.range(size_D, dtype=tf.int32)\n",
    "    selector_t = tf.slice(tf.map_fn(\n",
    "      lambda one: tf.random_shuffle(selector_1)  \n",
    "    , tf.ones([t, size_D], dtype=tf.int32)), [0,0], [t, size])\n",
    "    \n",
    "    return tf.gather(D, selector_t)\n",
    "\n",
    "def HM(X, D, t=500, psi = 20, lmbda=1.0, dt=tf.half):\n",
    "    size_X = tf.shape(X)[0]\n",
    "    dims_X = tf.shape(X)[1]\n",
    "    size_D = tf.shape(D)[0]\n",
    "    \n",
    "    ones_tX = tf.ones([t, size_X, dims_X], dtype=dt)  \n",
    "    \n",
    "    psi = tf.cond(tf.logical_and(tf.less(0, psi), tf.less(psi, size_D)), lambda: tf.constant(psi), lambda: size_D)\n",
    "    set_t_psi = tf.cond(psi<size_D, \n",
    "                        lambda: subsample(D, psi, t), \n",
    "                        # order of D will not matter and it will be broadcasted\n",
    "                        lambda: tf.expand_dims(D, 0)) \n",
    "    \n",
    "    ones_t_psi = tf.ones([t, psi, dims_X], dtype=dt) \n",
    "    \n",
    "    hm_X = tf.zeros([size_X], dtype=dt)\n",
    "    \n",
    "    directions = tf.random_uniform([t, dims_X], minval = -1, maxval = 1, dtype = dt)\n",
    "    projectors = tf.divide(directions, tf.norm(directions, axis=1, keep_dims=True))\n",
    "    \n",
    "    projects_X = tf.squeeze(tf.matmul(\n",
    "        tf.expand_dims(tf.multiply(ones_tX, tf.expand_dims(X, 0)), 2), \n",
    "        tf.expand_dims(tf.multiply(ones_tX, tf.expand_dims(projectors, 1)), 3)), [2, 3])\n",
    "    \n",
    "    projects_psi = tf.squeeze(tf.matmul(\n",
    "        tf.expand_dims(tf.multiply(ones_t_psi, set_t_psi), 2), \n",
    "        tf.expand_dims(tf.multiply(ones_t_psi, tf.expand_dims(projectors, 1)), 3)), [2, 3])\n",
    "    \n",
    "    mid_t_min = tf.add(\n",
    "        tf.multiply(tf.reduce_max(projects_psi, 1), (1-lmbda)/2),\n",
    "        tf.multiply(tf.reduce_min(projects_psi, 1), (1+lmbda)/2))\n",
    "    \n",
    "    mid_t_max = tf.add(\n",
    "        tf.multiply(tf.reduce_max(projects_psi, 1), (1+lmbda)/2),\n",
    "        tf.multiply(tf.reduce_min(projects_psi, 1), (1-lmbda)/2))\n",
    "    \n",
    "    mid_t = tf.add(mid_t_min, tf.multiply(tf.random_uniform([t], 0, 1, dtype=dt), tf.subtract(mid_t_max, mid_t_min)))\n",
    "    \n",
    "    mass_l_t = tf.divide(tf.reduce_sum(\n",
    "        tf.where(\n",
    "            tf.less(projects_psi, tf.expand_dims(mid_t, 1)), \n",
    "            tf.ones([t, psi], dtype=dt), \n",
    "            tf.zeros([t, psi], dtype=dt)), 1), tf.cast(psi, dtype=dt))\n",
    "    \n",
    "    mass_r_t = tf.add(tf.multiply(mass_l_t, -1), 1)\n",
    "    \n",
    "    mass_t = tf.where(tf.less(projects_X, tf.expand_dims(mid_t, 1)), \n",
    "                      tf.multiply(tf.ones([t, size_X], dtype=dt), tf.expand_dims(mass_l_t, 1)), \n",
    "                      tf.multiply(tf.ones([t, size_X], dtype=dt), tf.expand_dims(mass_r_t, 1)))\n",
    "    hs_mass = tf.reduce_mean(mass_t, 0)\n",
    "    return hs_mass\n",
    "\n",
    "kmass = tf.argmax(tf.concat([\n",
    "    tf.expand_dims(tf.divide(HM(vectors, cluster), tf.reduce_min(HM(vectors, cluster), 0, keep_dims=True)), 1)\n",
    "    for cluster in clusters\n",
    "], 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "# method = kmeans\n",
    "# method = kmedoids\n",
    "# method = kmass\n",
    "\n",
    "def run(method = kmeans, p=1, round_max=10, output=0):\n",
    "    assignment_values = initialize_clusters()\n",
    "    \n",
    "    # os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "    # tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    sess_config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    round_i = 0\n",
    "    keep_hurdle = num_vectors * p\n",
    "    keep_max = -1\n",
    "    best_result = assignment_values\n",
    "    best_round = 0\n",
    "\n",
    "    # drawClusters(assignment_values)\n",
    "    while round_i < round_max:    \n",
    "        round_i = round_i + 1\n",
    "        if output>1:\n",
    "            print(round_i)\n",
    "        with tf.Session(config=sess_config) as sess:\n",
    "            sess.run(init_op)\n",
    "            round_result = sess.run(method)\n",
    "\n",
    "            keep_count = np.sum([\n",
    "                1 if assignment_values[i]==round_result[i] else 0\n",
    "                for i in range(num_vectors)\n",
    "            ])\n",
    "            if output>1:\n",
    "                print(keep_count)\n",
    "            if keep_max < keep_count:\n",
    "                keep_max = keep_count\n",
    "                best_result = round_result\n",
    "                best_round=round_i\n",
    "                if output>1:\n",
    "                    print(\"best_result was updated.\")\n",
    "\n",
    "            assignment_values = sess.run(tf.assign(assignments, round_result))\n",
    "    #         drawClusters(assignment_values)\n",
    "            sess.close()\n",
    "        if keep_count >= keep_hurdle:\n",
    "            if output:\n",
    "                print(\"keep_hurdle was hit.\")\n",
    "            break\n",
    "\n",
    "    p = float(keep_max)/float(num_vectors)\n",
    "    if output>0:\n",
    "        print(\"The final P is \")\n",
    "        print(p)    \n",
    "        print(\"The round with best result is \")\n",
    "        print(best_round)\n",
    "        drawClusters(best_result)\n",
    "    return [best_result, p, best_round]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_runs = 40 # number of runs with random initialization for clustering evaluation.\n",
    "\n",
    "def evaluation_scores(groundtruth, labels_pred):\n",
    "    \"\"\"\n",
    "    Eval scores of the predicted results.\n",
    "     \n",
    "    :param: groundtruth (type list): the groundtruth (GT) of cluster assignment. Each element denotes an item's GT cluster_id. \n",
    "    :param: labels_pred (type list): the predicted cluster assignments. Each element denotes an item's predicted cluster_id.\n",
    "    \"\"\"\n",
    "    NMI = normalized_mutual_info_score(groundtruth,labels_pred)\n",
    "    A = accuracy(groundtruth,labels_pred)\n",
    "    F1 = f_measure(groundtruth,labels_pred)\n",
    "    P = purity(groundtruth,labels_pred)\n",
    "    RI = random_index(groundtruth,labels_pred)\n",
    "    ARI = adjusted_rand_score(groundtruth,labels_pred)\n",
    "    map_pairs = get_map_pairs(groundtruth,labels_pred)\n",
    "    return NMI, A, F1, P, RI, ARI, map_pairs\n",
    "    \n",
    "def evaluation(method = kmeans):    \n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    NMIs,As,F1s = [],[],[]\n",
    "    i_run = 1\n",
    "    labels_unique = np.unique(labels)\n",
    "    labels_indexed = []\n",
    "    for label in labels:\n",
    "        labels_indexed.append(np.where(labels_unique==label))\n",
    "    labels_indexed = np.squeeze(labels_indexed)\n",
    "    print(\"Round\\tTime\\tAcc\\tF1\\tNMI\\tp\\tl\")\n",
    "    while i_run <= n_runs:\n",
    "        t1 = time.time()\n",
    "        [result, p, l] = run(method = method, output=0)\n",
    "        NMI,A,F1,P,RI,ARI,map_pairs = evaluation_scores(labels_indexed, result)\n",
    "        tt = (time.time()-t1)\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            i_run, \n",
    "            \"{0:.2f}\".format(time.time()-t1), \n",
    "            \"{0:.2f}\".format(A), \n",
    "            \"{0:.2f}\".format(F1), \n",
    "            \"{0:.2f}\".format(NMI),\n",
    "            \"{0:.2f}\".format(p),\n",
    "            l\n",
    "        ))\n",
    "        i_run = i_run+1\n",
    "        NMIs.append(NMI)\n",
    "        As.append(A)\n",
    "        F1s.append(F1)\n",
    "\n",
    "    print(\"Results of {} runs (mean,std_var,min,max):\\n\\t Acc: {}, {}, {}, {}\\n\\t F1 : {}, {}, {}, {}\\n\\t NMI: {}, {}, {}, {}\"\n",
    "          .format(n_runs\n",
    "                  , np.mean(As),np.std(As), np.min(As), np.max(As)\n",
    "                  , np.mean(F1s),np.std(F1s), np.min(F1s), np.max(F1s)\n",
    "                  , np.mean(NMIs),np.std(NMIs), np.min(NMIs), np.max(NMIs)))\n",
    "    print(\"Running time: {}s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\tTime\tAcc\tF1\tNMI\tp\tl\n",
      "1\t227.12\t0.56\t0.48\t0.43\t0.78\t8\n",
      "2\t225.73\t0.55\t0.52\t0.43\t0.87\t5\n",
      "3\t221.13\t0.55\t0.44\t0.40\t0.84\t3\n",
      "4\t219.59\t0.53\t0.44\t0.39\t0.79\t4\n",
      "5\t222.43\t0.58\t0.51\t0.45\t0.85\t9\n",
      "6\t224.51\t0.60\t0.57\t0.44\t0.81\t4\n",
      "7\t217.62\t0.59\t0.54\t0.44\t0.85\t3\n",
      "8\t216.29\t0.69\t0.58\t0.49\t0.71\t4\n",
      "9\t221.08\t0.52\t0.44\t0.41\t0.82\t2\n",
      "10\t216.47\t0.60\t0.54\t0.47\t0.88\t6\n",
      "11\t218.36\t0.64\t0.62\t0.46\t0.80\t9\n",
      "12\t218.96\t0.54\t0.52\t0.44\t0.88\t2\n",
      "13\t226.87\t0.59\t0.56\t0.45\t0.76\t8\n",
      "14\t225.00\t0.69\t0.65\t0.46\t0.79\t3\n",
      "15\t226.15\t0.59\t0.54\t0.42\t0.86\t6\n",
      "16\t225.22\t0.58\t0.53\t0.43\t0.84\t6\n",
      "17\t218.38\t0.58\t0.54\t0.40\t0.80\t8\n",
      "18\t217.10\t0.53\t0.51\t0.44\t0.75\t7\n",
      "19\t229.51\t0.47\t0.41\t0.41\t0.88\t8\n",
      "20\t234.61\t0.54\t0.55\t0.41\t0.87\t9\n",
      "21\t238.49\t0.57\t0.53\t0.41\t0.86\t7\n",
      "22\t227.02\t0.60\t0.55\t0.42\t0.78\t6\n",
      "23\t225.94\t0.61\t0.58\t0.47\t0.75\t10\n",
      "24\t226.70\t0.65\t0.56\t0.45\t0.79\t8\n",
      "25\t232.44\t0.58\t0.53\t0.42\t0.85\t7\n",
      "26\t229.65\t0.60\t0.55\t0.47\t0.87\t9\n",
      "27\t225.70\t0.58\t0.51\t0.46\t0.84\t9\n",
      "28\t223.93\t0.56\t0.50\t0.41\t0.77\t6\n",
      "29\t228.68\t0.60\t0.52\t0.43\t0.79\t10\n",
      "30\t225.21\t0.60\t0.55\t0.49\t0.82\t3\n",
      "31\t219.72\t0.58\t0.56\t0.45\t0.78\t6\n",
      "32\t220.59\t0.61\t0.54\t0.42\t0.82\t6\n",
      "33\t221.86\t0.57\t0.55\t0.44\t0.82\t6\n",
      "34\t217.35\t0.57\t0.51\t0.47\t0.83\t9\n",
      "35\t248.46\t0.56\t0.52\t0.41\t0.83\t8\n",
      "36\t229.43\t0.58\t0.54\t0.44\t0.89\t6\n",
      "37\t229.99\t0.54\t0.48\t0.40\t0.77\t8\n",
      "38\t222.25\t0.57\t0.50\t0.45\t0.89\t10\n",
      "39\t222.14\t0.66\t0.59\t0.45\t0.78\t6\n",
      "40\t236.00\t0.62\t0.59\t0.48\t0.79\t10\n",
      "Results of 40 runs (mean,std_var,min,max):\n",
      "\t Acc: 0.5837091319052987, 0.04300430971312324, 0.46786922209695603, 0.6904171364148817\n",
      "\t F1 : 0.531239336614427, 0.04794818053269932, 0.4053775822188026, 0.652989947599377\n",
      "\t NMI: 0.43758340347327546, 0.024726130714018628, 0.39433894658764257, 0.4920795506246983\n",
      "Running time: 9007.269653081894s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\tTime\tAcc\tF1\tNMI\tp\tl\n",
      "1\t4.40\t0.62\t0.62\t0.45\t1.00\t2\n",
      "2\t3.24\t0.62\t0.62\t0.45\t1.00\t2\n",
      "3\t3.11\t0.62\t0.62\t0.45\t1.00\t2\n",
      "4\t3.18\t0.62\t0.62\t0.45\t1.00\t2\n",
      "5\t3.23\t0.62\t0.62\t0.45\t1.00\t2\n",
      "6\t3.09\t0.62\t0.62\t0.45\t1.00\t2\n",
      "7\t3.11\t0.62\t0.62\t0.45\t1.00\t2\n",
      "8\t3.44\t0.62\t0.62\t0.45\t1.00\t2\n",
      "9\t3.34\t0.62\t0.62\t0.45\t1.00\t2\n",
      "10\t3.39\t0.62\t0.62\t0.45\t1.00\t2\n",
      "11\t3.34\t0.62\t0.62\t0.45\t1.00\t2\n",
      "12\t3.15\t0.62\t0.62\t0.45\t1.00\t2\n",
      "13\t3.34\t0.62\t0.62\t0.45\t1.00\t2\n",
      "14\t3.19\t0.62\t0.62\t0.45\t1.00\t2\n",
      "15\t3.26\t0.62\t0.62\t0.45\t1.00\t2\n",
      "16\t3.13\t0.62\t0.62\t0.45\t1.00\t2\n",
      "17\t3.25\t0.62\t0.62\t0.45\t1.00\t2\n",
      "18\t3.19\t0.62\t0.62\t0.45\t1.00\t2\n",
      "19\t3.27\t0.62\t0.62\t0.45\t1.00\t2\n",
      "20\t3.13\t0.62\t0.62\t0.45\t1.00\t2\n",
      "21\t3.31\t0.62\t0.62\t0.45\t1.00\t2\n",
      "22\t3.29\t0.62\t0.62\t0.45\t1.00\t2\n",
      "23\t3.34\t0.62\t0.62\t0.45\t1.00\t2\n",
      "24\t3.21\t0.62\t0.62\t0.45\t1.00\t2\n",
      "25\t3.39\t0.62\t0.62\t0.45\t1.00\t2\n",
      "26\t3.21\t0.62\t0.62\t0.45\t1.00\t2\n",
      "27\t3.34\t0.62\t0.62\t0.45\t1.00\t2\n",
      "28\t3.17\t0.62\t0.62\t0.45\t1.00\t2\n",
      "29\t3.21\t0.62\t0.62\t0.45\t1.00\t2\n",
      "30\t3.27\t0.62\t0.62\t0.45\t1.00\t2\n",
      "31\t3.36\t0.62\t0.62\t0.45\t1.00\t2\n",
      "32\t3.28\t0.62\t0.62\t0.45\t1.00\t2\n",
      "33\t3.31\t0.62\t0.62\t0.45\t1.00\t2\n",
      "34\t3.20\t0.62\t0.62\t0.45\t1.00\t2\n",
      "35\t3.36\t0.62\t0.62\t0.45\t1.00\t2\n",
      "36\t3.25\t0.62\t0.62\t0.45\t1.00\t2\n",
      "37\t3.33\t0.62\t0.62\t0.45\t1.00\t2\n",
      "38\t3.23\t0.62\t0.62\t0.45\t1.00\t2\n",
      "39\t3.30\t0.62\t0.62\t0.45\t1.00\t2\n",
      "40\t3.36\t0.62\t0.62\t0.45\t1.00\t2\n",
      "Results of 40 runs (mean,std_var,min,max):\n",
      "\t Acc: 0.6198421645997745, 0.0, 0.6198421645997745, 0.6198421645997745\n",
      "\t F1 : 0.6207834130714214, 0.0, 0.6207834130714214, 0.6207834130714214\n",
      "\t NMI: 0.44794767875051134, 5.551115123125783e-17, 0.4479476787505114, 0.4479476787505114\n",
      "Running time: 131.51472067832947s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\tTime\tAcc\tF1\tNMI\tp\tl\n",
      "1\t3.38\t0.47\t0.44\t0.36\t1.00\t2\n",
      "2\t3.31\t0.47\t0.44\t0.36\t1.00\t2\n",
      "3\t3.43\t0.47\t0.44\t0.36\t1.00\t2\n",
      "4\t3.49\t0.47\t0.44\t0.36\t1.00\t2\n",
      "5\t3.30\t0.47\t0.44\t0.36\t1.00\t2\n",
      "6\t3.42\t0.47\t0.44\t0.36\t1.00\t2\n",
      "7\t3.29\t0.47\t0.44\t0.36\t1.00\t2\n",
      "8\t3.43\t0.47\t0.44\t0.36\t1.00\t2\n",
      "9\t3.28\t0.47\t0.44\t0.36\t1.00\t2\n",
      "10\t3.43\t0.47\t0.44\t0.36\t1.00\t2\n",
      "11\t3.47\t0.47\t0.44\t0.36\t1.00\t2\n",
      "12\t3.35\t0.47\t0.44\t0.36\t1.00\t2\n",
      "13\t3.30\t0.47\t0.44\t0.36\t1.00\t2\n",
      "14\t3.56\t0.47\t0.44\t0.36\t1.00\t2\n",
      "15\t3.50\t0.47\t0.44\t0.36\t1.00\t2\n",
      "16\t3.35\t0.47\t0.44\t0.36\t1.00\t2\n",
      "17\t3.53\t0.47\t0.44\t0.36\t1.00\t2\n",
      "18\t3.40\t0.47\t0.44\t0.36\t1.00\t2\n",
      "19\t3.48\t0.47\t0.44\t0.36\t1.00\t2\n",
      "20\t3.37\t0.47\t0.44\t0.36\t1.00\t2\n",
      "21\t3.47\t0.47\t0.44\t0.36\t1.00\t2\n",
      "22\t3.34\t0.47\t0.44\t0.36\t1.00\t2\n",
      "23\t3.52\t0.47\t0.44\t0.36\t1.00\t2\n",
      "24\t3.36\t0.47\t0.44\t0.36\t1.00\t2\n",
      "25\t3.47\t0.47\t0.44\t0.36\t1.00\t2\n",
      "26\t3.52\t0.47\t0.44\t0.36\t1.00\t2\n",
      "27\t3.49\t0.47\t0.44\t0.36\t1.00\t2\n",
      "28\t3.55\t0.47\t0.44\t0.36\t1.00\t2\n",
      "29\t3.49\t0.47\t0.44\t0.36\t1.00\t2\n",
      "30\t3.47\t0.47\t0.44\t0.36\t1.00\t2\n",
      "31\t3.52\t0.47\t0.44\t0.36\t1.00\t2\n",
      "32\t3.35\t0.47\t0.44\t0.36\t1.00\t2\n",
      "33\t3.55\t0.47\t0.44\t0.36\t1.00\t2\n",
      "34\t3.39\t0.47\t0.44\t0.36\t1.00\t2\n",
      "35\t3.57\t0.47\t0.44\t0.36\t1.00\t2\n",
      "36\t3.51\t0.47\t0.44\t0.36\t1.00\t2\n",
      "37\t3.49\t0.47\t0.44\t0.36\t1.00\t2\n",
      "38\t3.53\t0.47\t0.44\t0.36\t1.00\t2\n",
      "39\t3.42\t0.47\t0.44\t0.36\t1.00\t2\n",
      "40\t3.57\t0.47\t0.44\t0.36\t1.00\t2\n",
      "Results of 40 runs (mean,std_var,min,max):\n",
      "\t Acc: 0.46741826381059753, 0.0, 0.46741826381059753, 0.46741826381059753\n",
      "\t F1 : 0.4355981169320722, 0.0, 0.4355981169320722, 0.4355981169320722\n",
      "\t NMI: 0.3568407700263119, 0.0, 0.3568407700263119, 0.3568407700263119\n",
      "Running time: 137.67037844657898s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmedoids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
