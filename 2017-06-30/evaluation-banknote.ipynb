{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autotime\n",
    "\n",
    "import os\n",
    "import re\n",
    "import io\n",
    "import wget\n",
    "\n",
    "# Define how to get data\n",
    "def get_iris(storage_folder=\"temp\", data_file=\"iris_data.txt\", splitter=','):\n",
    "    data_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):        \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def get_satellite(storage_folder=\"temp\", data_file=\"satellite_data.txt\", splitter=' '):\n",
    "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.trn'\n",
    "    # data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/satimage/sat.tst'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):           \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "def get_banknote(storage_folder=\"temp\", data_file=\"banknote_data.txt\", splitter=','):\n",
    "    data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
    "    # Make a storage folder for models and data\n",
    "    if not os.path.exists(storage_folder):\n",
    "        os.makedirs(storage_folder)\n",
    "        \n",
    "    data_path = os.path.join(storage_folder, data_file)\n",
    "    \n",
    "    if not os.path.isfile(os.path.join(storage_folder, data_file)):           \n",
    "        _ = wget.download(data_url, data_path) \n",
    "\n",
    "    data = [l.strip() for l in open(data_path) if l.strip()]\n",
    "    features = [tuple(map(float, x.split(splitter)[:-1])) for x in data]\n",
    "    labels = [x.split(splitter)[-1] for x in data]\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "vector_values, labels = get_banknote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: \n",
      "{'0', '1'}\n",
      "Sample size: \n",
      "1372\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "num_clusters = len(set(labels))\n",
    "num_vectors = len(vector_values)\n",
    "\n",
    "print(\"Labels: \")\n",
    "print(set(labels))\n",
    "print(\"Sample size: \")\n",
    "print(num_vectors)\n",
    "\n",
    "vectors = tf.constant(vector_values, dtype = tf.half)\n",
    "\n",
    "npArray = np.array(vector_values)\n",
    "mlab_pca = mlabPCA(npArray)\n",
    "users_2d = mlab_pca.project(npArray, minfrac=mlab_pca.fracs[1])\n",
    "\n",
    "def drawClusters(assignment_values):\n",
    "    data = {\"x\": [], \"y\": [], \"cluster\": []}\n",
    "    for i in range(len(assignment_values)):\n",
    "        data[\"x\"].append(users_2d[i][0])\n",
    "        data[\"y\"].append(users_2d[i][1])\n",
    "        data[\"cluster\"].append(assignment_values[i])\n",
    "    df = pd.DataFrame(data)\n",
    "    sns.lmplot(\"x\", \"y\", data=df, \n",
    "               fit_reg=False, size=7, \n",
    "               hue=\"cluster\", legend=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_clusters():\n",
    "    X = vector_values\n",
    "    n = np.shape(X)[0]\n",
    "    d = np.shape(X)[1]\n",
    "    K = num_clusters\n",
    "    S = np.ones(K)*(int(n/K))\n",
    "    S[K-1] = S[K-1] + n%K\n",
    "    \n",
    "    Y = np.zeros([n, 1])\n",
    "    for i in range(K):\n",
    "        yis0 = np.where(Y==0)[0]\n",
    "        a = np.take(X, yis0, axis=0)\n",
    "        b = np.random.randn(d, 1)\n",
    "        xt = np.squeeze(np.dot(a, b))\n",
    "        inx = np.argsort(xt)\n",
    "        Y[yis0[inx[range(int(S[i]))]]]=i\n",
    "    return np.squeeze(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteration variable\n",
    "assignments = tf.Variable(initialize_clusters(), dtype=tf.int64)\n",
    "\n",
    "#clusters are based on assignments\n",
    "clusters = [tf.gather(vectors, tf.squeeze(tf.where(tf.equal(assignments, c)), squeeze_dims=[1])) for c in range(num_clusters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossDistance(a, b, ord='euclidean'):\n",
    "    diff = tf.subtract(tf.expand_dims(a, 0), tf.expand_dims(b, 1))\n",
    "    result = tf.norm(diff, ord, 2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 93 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "means = tf.concat([\n",
    "    tf.expand_dims(tf.reduce_mean(cluster, 0), 0) \n",
    "    for cluster in clusters], 0)\n",
    "kmeans = tf.argmin(crossDistance(vectors, means), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "medoids = tf.concat([\n",
    "    tf.expand_dims(tf.gather(cluster, tf.argmin(tf.reduce_sum(crossDistance(cluster, cluster), 0), 0)), 0)\n",
    "    for cluster in clusters], 0)\n",
    "kmedoids = tf.argmin(crossDistance(vectors, medoids), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 782 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def subsample(D, size, t):\n",
    "    size_D = tf.shape(D)[0]\n",
    "    selector_1 = tf.range(size_D, dtype=tf.int32)\n",
    "    selector_t = tf.slice(tf.map_fn(\n",
    "      lambda one: tf.random_shuffle(selector_1)  \n",
    "    , tf.ones([t, size_D], dtype=tf.int32)), [0,0], [t, size])\n",
    "    \n",
    "    return tf.gather(D, selector_t)\n",
    "\n",
    "def HM(X, D, t=500, psi = 20, lmbda=1.0, dt=tf.half):\n",
    "    size_X = tf.shape(X)[0]\n",
    "    dims_X = tf.shape(X)[1]\n",
    "    size_D = tf.shape(D)[0]\n",
    "    \n",
    "    ones_tX = tf.ones([t, size_X, dims_X], dtype=dt)  \n",
    "    \n",
    "    psi = tf.cond(tf.logical_and(tf.less(0, psi), tf.less(psi, size_D)), lambda: tf.constant(psi), lambda: size_D)\n",
    "    set_t_psi = tf.cond(psi<size_D, \n",
    "                        lambda: subsample(D, psi, t), \n",
    "                        # order of D will not matter and it will be broadcasted\n",
    "                        lambda: tf.expand_dims(D, 0)) \n",
    "    \n",
    "    ones_t_psi = tf.ones([t, psi, dims_X], dtype=dt) \n",
    "    \n",
    "    hm_X = tf.zeros([size_X], dtype=dt)\n",
    "    \n",
    "    directions = tf.random_uniform([t, dims_X], minval = -1, maxval = 1, dtype = dt)\n",
    "    projectors = tf.divide(directions, tf.norm(directions, axis=1, keep_dims=True))\n",
    "    \n",
    "    projects_X = tf.squeeze(tf.matmul(\n",
    "        tf.expand_dims(tf.multiply(ones_tX, tf.expand_dims(X, 0)), 2), \n",
    "        tf.expand_dims(tf.multiply(ones_tX, tf.expand_dims(projectors, 1)), 3)), [2, 3])\n",
    "    \n",
    "    projects_psi = tf.squeeze(tf.matmul(\n",
    "        tf.expand_dims(tf.multiply(ones_t_psi, set_t_psi), 2), \n",
    "        tf.expand_dims(tf.multiply(ones_t_psi, tf.expand_dims(projectors, 1)), 3)), [2, 3])\n",
    "    \n",
    "    mid_t_min = tf.add(\n",
    "        tf.multiply(tf.reduce_max(projects_psi, 1), (1-lmbda)/2),\n",
    "        tf.multiply(tf.reduce_min(projects_psi, 1), (1+lmbda)/2))\n",
    "    \n",
    "    mid_t_max = tf.add(\n",
    "        tf.multiply(tf.reduce_max(projects_psi, 1), (1+lmbda)/2),\n",
    "        tf.multiply(tf.reduce_min(projects_psi, 1), (1-lmbda)/2))\n",
    "    \n",
    "    mid_t = tf.add(mid_t_min, tf.multiply(tf.random_uniform([t], 0, 1, dtype=dt), tf.subtract(mid_t_max, mid_t_min)))\n",
    "    \n",
    "    mass_l_t = tf.divide(tf.reduce_sum(\n",
    "        tf.where(\n",
    "            tf.less(projects_psi, tf.expand_dims(mid_t, 1)), \n",
    "            tf.ones([t, psi], dtype=dt), \n",
    "            tf.zeros([t, psi], dtype=dt)), 1), tf.cast(psi, dtype=dt))\n",
    "    \n",
    "    mass_r_t = tf.add(tf.multiply(mass_l_t, -1), 1)\n",
    "    \n",
    "    mass_t = tf.where(tf.less(projects_X, tf.expand_dims(mid_t, 1)), \n",
    "                      tf.multiply(tf.ones([t, size_X], dtype=dt), tf.expand_dims(mass_l_t, 1)), \n",
    "                      tf.multiply(tf.ones([t, size_X], dtype=dt), tf.expand_dims(mass_r_t, 1)))\n",
    "    hs_mass = tf.reduce_mean(mass_t, 0)\n",
    "    return hs_mass\n",
    "\n",
    "kmass = tf.argmax(tf.concat([\n",
    "    tf.expand_dims(tf.divide(HM(vectors, cluster), tf.reduce_min(HM(vectors, cluster), 0, keep_dims=True)), 1)\n",
    "    for cluster in clusters\n",
    "], 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "\n",
    "# method = kmeans\n",
    "# method = kmedoids\n",
    "# method = kmass\n",
    "\n",
    "def run(method = kmeans, p=1, round_max=10, output=0):\n",
    "    assignment_values = initialize_clusters()\n",
    "    \n",
    "    # os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "    # tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    sess_config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    round_i = 0\n",
    "    keep_hurdle = num_vectors * p\n",
    "    keep_max = -1\n",
    "    best_result = assignment_values\n",
    "    best_round = 0\n",
    "\n",
    "    # drawClusters(assignment_values)\n",
    "    while round_i < round_max:    \n",
    "        round_i = round_i + 1\n",
    "        if output>1:\n",
    "            print(round_i)\n",
    "        with tf.Session(config=sess_config) as sess:\n",
    "            sess.run(init_op)\n",
    "            round_result = sess.run(method)\n",
    "\n",
    "            keep_count = np.sum([\n",
    "                1 if assignment_values[i]==round_result[i] else 0\n",
    "                for i in range(num_vectors)\n",
    "            ])\n",
    "            if output>1:\n",
    "                print(keep_count)\n",
    "            if keep_max < keep_count:\n",
    "                keep_max = keep_count\n",
    "                best_result = round_result\n",
    "                best_round=round_i\n",
    "                if output>1:\n",
    "                    print(\"best_result was updated.\")\n",
    "\n",
    "            assignment_values = sess.run(tf.assign(assignments, round_result))\n",
    "    #         drawClusters(assignment_values)\n",
    "            sess.close()\n",
    "        if keep_count >= keep_hurdle:\n",
    "            if output:\n",
    "                print(\"keep_hurdle was hit.\")\n",
    "            break\n",
    "\n",
    "    if output>0:\n",
    "        print(\"The final P is \")\n",
    "        p = float(keep_max)/float(num_vectors)\n",
    "        print(p)    \n",
    "        print(\"The round with best result is \")\n",
    "        print(best_round)\n",
    "        drawClusters(best_result)\n",
    "    return [best_result, p, best_round]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 40 # number of runs with random initialization for clustering evaluation.\n",
    "\n",
    "def evaluation_scores(groundtruth, labels_pred):\n",
    "    \"\"\"\n",
    "    Eval scores of the predicted results.\n",
    "     \n",
    "    :param: groundtruth (type list): the groundtruth (GT) of cluster assignment. Each element denotes an item's GT cluster_id. \n",
    "    :param: labels_pred (type list): the predicted cluster assignments. Each element denotes an item's predicted cluster_id.\n",
    "    \"\"\"\n",
    "    NMI = normalized_mutual_info_score(groundtruth,labels_pred)\n",
    "    A = accuracy(groundtruth,labels_pred)\n",
    "    F1 = f_measure(groundtruth,labels_pred)\n",
    "    P = purity(groundtruth,labels_pred)\n",
    "    RI = random_index(groundtruth,labels_pred)\n",
    "    ARI = adjusted_rand_score(groundtruth,labels_pred)\n",
    "    map_pairs = get_map_pairs(groundtruth,labels_pred)\n",
    "    return NMI, A, F1, P, RI, ARI, map_pairs\n",
    "    \n",
    "def evaluation(method = kmeans):    \n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    NMIs,As,F1s = [],[],[]\n",
    "    i_run = 1\n",
    "    labels_unique = np.unique(labels)\n",
    "    labels_indexed = []\n",
    "    for label in labels:\n",
    "        labels_indexed.append(np.where(labels_unique==label))\n",
    "    labels_indexed = np.squeeze(labels_indexed)\n",
    "    print(\"Round\\tTime\\tAcc\\tF1\\tNMI\\tp\\tl\")\n",
    "    while i_run <= n_runs:\n",
    "        t1 = time.time()\n",
    "        [result, p, l] = run(method = method, output=0)\n",
    "        NMI,A,F1,P,RI,ARI,map_pairs = evaluation_scores(labels_indexed, result)\n",
    "        tt = (time.time()-t1)\n",
    "        print(\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\\t{}\".format(\n",
    "            i_run, \n",
    "            \"{0:.2f}\".format(time.time()-t1), \n",
    "            \"{0:.2f}\".format(A), \n",
    "            \"{0:.2f}\".format(F1), \n",
    "            \"{0:.2f}\".format(NMI),\n",
    "            \"{0:.2f}\".format(p),\n",
    "            l\n",
    "        ))\n",
    "        i_run = i_run+1\n",
    "        NMIs.append(NMI)\n",
    "        As.append(A)\n",
    "        F1s.append(F1)\n",
    "\n",
    "    print(\"Results of {} runs (mean,std_var,min,max):\\n\\t Acc: {}, {}, {}, {}\\n\\t F1 : {}, {}, {}, {}\\n\\t NMI: {}, {}, {}, {}\"\n",
    "          .format(n_runs\n",
    "                  , np.mean(As),np.std(As), np.min(As), np.max(As)\n",
    "                  , np.mean(F1s),np.std(F1s), np.min(F1s), np.max(F1s)\n",
    "                  , np.mean(NMIs),np.std(NMIs), np.min(NMIs), np.max(NMIs)))\n",
    "    print(\"Running time: {}s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\tTime\tAcc\tF1\tNMI\tp\tl\n",
      "1\t11.47\t0.67\t0.67\t0.09\t1.00\t2\n",
      "2\t10.60\t0.63\t0.63\t0.06\t1.00\t7\n",
      "3\t10.64\t0.66\t0.66\t0.08\t1.00\t10\n",
      "4\t10.71\t0.71\t0.70\t0.31\t1.00\t6\n",
      "5\t10.98\t0.65\t0.64\t0.06\t1.00\t9\n",
      "6\t10.96\t0.74\t0.73\t0.29\t1.00\t4\n",
      "7\t10.82\t0.64\t0.63\t0.05\t1.00\t9\n",
      "8\t11.05\t0.67\t0.67\t0.09\t1.00\t7\n",
      "9\t10.97\t0.70\t0.69\t0.19\t1.00\t9\n",
      "10\t11.55\t0.64\t0.64\t0.06\t1.00\t10\n",
      "11\t11.32\t0.71\t0.71\t0.19\t1.00\t5\n",
      "12\t11.49\t0.71\t0.70\t0.25\t1.00\t8\n",
      "13\t11.26\t0.67\t0.67\t0.09\t1.00\t4\n",
      "14\t11.37\t0.69\t0.68\t0.14\t1.00\t10\n",
      "15\t11.38\t0.65\t0.65\t0.07\t1.00\t8\n",
      "16\t11.50\t0.68\t0.68\t0.11\t1.00\t2\n",
      "17\t11.50\t0.62\t0.61\t0.04\t1.00\t10\n",
      "18\t11.65\t0.68\t0.68\t0.12\t1.00\t10\n",
      "19\t11.66\t0.71\t0.71\t0.19\t1.00\t2\n",
      "20\t11.71\t0.64\t0.64\t0.06\t1.00\t5\n",
      "21\t11.91\t0.70\t0.70\t0.15\t1.00\t10\n",
      "22\t11.96\t0.74\t0.74\t0.33\t1.00\t7\n",
      "23\t12.46\t0.64\t0.64\t0.06\t1.00\t3\n",
      "24\t12.30\t0.64\t0.64\t0.06\t1.00\t2\n",
      "25\t12.35\t0.64\t0.64\t0.06\t1.00\t4\n",
      "26\t12.39\t0.65\t0.65\t0.08\t1.00\t9\n",
      "27\t12.43\t0.66\t0.66\t0.08\t1.00\t6\n",
      "28\t12.56\t0.63\t0.63\t0.05\t1.00\t2\n",
      "29\t12.48\t0.66\t0.66\t0.08\t1.00\t9\n",
      "30\t12.68\t0.64\t0.64\t0.06\t1.00\t4\n",
      "31\t12.64\t0.62\t0.62\t0.04\t1.00\t2\n",
      "32\t12.84\t0.68\t0.68\t0.11\t1.00\t6\n",
      "33\t12.99\t0.66\t0.66\t0.09\t1.00\t10\n",
      "34\t13.63\t0.72\t0.72\t0.23\t1.00\t6\n",
      "35\t13.36\t0.72\t0.71\t0.21\t1.00\t10\n",
      "36\t13.18\t0.74\t0.73\t0.31\t1.00\t8\n",
      "37\t13.33\t0.70\t0.69\t0.30\t1.00\t8\n",
      "38\t13.17\t0.64\t0.64\t0.07\t1.00\t10\n",
      "39\t13.72\t0.65\t0.65\t0.07\t1.00\t2\n",
      "40\t13.53\t0.63\t0.63\t0.05\t1.00\t8\n",
      "Results of 40 runs (mean,std_var,min,max):\n",
      "\t Acc: 0.6706997084548105, 0.03490911259741002, 0.6202623906705539, 0.7419825072886297\n",
      "\t F1 : 0.6685766009072986, 0.03365689983504252, 0.6117631403809023, 0.7367185111415755\n",
      "\t NMI: 0.12617271092890642, 0.08702461315487622, 0.03737274147550921, 0.3278692533904552\n",
      "Running time: 480.5239734649658s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\tTime\tAcc\tF1\tNMI\tp\tl\n",
      "1\t1.15\t0.61\t0.61\t0.03\t1.00\t2\n",
      "2\t1.13\t0.61\t0.61\t0.03\t1.00\t2\n",
      "3\t1.14\t0.61\t0.61\t0.03\t1.00\t2\n",
      "4\t1.14\t0.61\t0.61\t0.03\t1.00\t2\n",
      "5\t1.15\t0.61\t0.61\t0.03\t1.00\t2\n",
      "6\t1.18\t0.61\t0.61\t0.03\t1.00\t2\n",
      "7\t1.25\t0.61\t0.61\t0.03\t1.00\t2\n",
      "8\t1.16\t0.61\t0.61\t0.03\t1.00\t2\n",
      "9\t1.16\t0.61\t0.61\t0.03\t1.00\t2\n",
      "10\t1.18\t0.61\t0.61\t0.03\t1.00\t2\n",
      "11\t1.16\t0.61\t0.61\t0.03\t1.00\t2\n",
      "12\t1.17\t0.61\t0.61\t0.03\t1.00\t2\n",
      "13\t1.17\t0.61\t0.61\t0.03\t1.00\t2\n",
      "14\t1.17\t0.61\t0.61\t0.03\t1.00\t2\n",
      "15\t1.28\t0.61\t0.61\t0.03\t1.00\t2\n",
      "16\t1.18\t0.61\t0.61\t0.03\t1.00\t2\n",
      "17\t1.20\t0.61\t0.61\t0.03\t1.00\t2\n",
      "18\t1.18\t0.61\t0.61\t0.03\t1.00\t2\n",
      "19\t1.22\t0.61\t0.61\t0.03\t1.00\t2\n",
      "20\t1.21\t0.61\t0.61\t0.03\t1.00\t2\n",
      "21\t1.38\t0.61\t0.61\t0.03\t1.00\t2\n",
      "22\t1.23\t0.61\t0.61\t0.03\t1.00\t2\n",
      "23\t1.21\t0.61\t0.61\t0.03\t1.00\t2\n",
      "24\t1.20\t0.61\t0.61\t0.03\t1.00\t2\n",
      "25\t1.22\t0.61\t0.61\t0.03\t1.00\t2\n",
      "26\t1.22\t0.61\t0.61\t0.03\t1.00\t2\n",
      "27\t1.21\t0.61\t0.61\t0.03\t1.00\t2\n",
      "28\t1.31\t0.61\t0.61\t0.03\t1.00\t2\n",
      "29\t1.22\t0.61\t0.61\t0.03\t1.00\t2\n",
      "30\t1.26\t0.61\t0.61\t0.03\t1.00\t2\n",
      "31\t1.23\t0.61\t0.61\t0.03\t1.00\t2\n",
      "32\t1.33\t0.61\t0.61\t0.03\t1.00\t2\n",
      "33\t1.22\t0.61\t0.61\t0.03\t1.00\t2\n",
      "34\t1.23\t0.61\t0.61\t0.03\t1.00\t2\n",
      "35\t1.27\t0.61\t0.61\t0.03\t1.00\t2\n",
      "36\t1.29\t0.61\t0.61\t0.03\t1.00\t2\n",
      "37\t1.31\t0.61\t0.61\t0.03\t1.00\t2\n",
      "38\t1.45\t0.61\t0.61\t0.03\t1.00\t2\n",
      "39\t1.33\t0.61\t0.61\t0.03\t1.00\t2\n",
      "40\t1.27\t0.61\t0.61\t0.03\t1.00\t2\n",
      "Results of 40 runs (mean,std_var,min,max):\n",
      "\t Acc: 0.6100583090379009, 0.0, 0.6100583090379009, 0.6100583090379009\n",
      "\t F1 : 0.606470647204477, 0.0, 0.606470647204477, 0.606470647204477\n",
      "\t NMI: 0.033206512964347464, 0.0, 0.033206512964347464, 0.033206512964347464\n",
      "Running time: 48.98547911643982s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round\tTime\tAcc\tF1\tNMI\tp\tl\n",
      "1\t1.29\t0.63\t0.63\t0.05\t1.00\t2\n",
      "2\t1.27\t0.63\t0.63\t0.05\t1.00\t2\n",
      "3\t1.39\t0.63\t0.63\t0.05\t1.00\t2\n",
      "4\t1.32\t0.63\t0.63\t0.05\t1.00\t2\n",
      "5\t1.38\t0.63\t0.63\t0.05\t1.00\t2\n",
      "6\t1.40\t0.63\t0.63\t0.05\t1.00\t2\n",
      "7\t1.45\t0.63\t0.63\t0.05\t1.00\t2\n",
      "8\t1.33\t0.63\t0.63\t0.05\t1.00\t2\n",
      "9\t1.38\t0.63\t0.63\t0.05\t1.00\t2\n",
      "10\t1.34\t0.63\t0.63\t0.05\t1.00\t2\n",
      "11\t1.32\t0.63\t0.63\t0.05\t1.00\t2\n",
      "12\t1.48\t0.63\t0.63\t0.05\t1.00\t2\n",
      "13\t1.39\t0.63\t0.63\t0.05\t1.00\t2\n",
      "14\t1.37\t0.63\t0.63\t0.05\t1.00\t2\n",
      "15\t1.42\t0.63\t0.63\t0.05\t1.00\t2\n",
      "16\t1.48\t0.63\t0.63\t0.05\t1.00\t2\n",
      "17\t1.36\t0.63\t0.63\t0.05\t1.00\t2\n",
      "18\t1.41\t0.63\t0.63\t0.05\t1.00\t2\n",
      "19\t1.38\t0.63\t0.63\t0.05\t1.00\t2\n",
      "20\t1.48\t0.63\t0.63\t0.05\t1.00\t2\n",
      "21\t1.31\t0.63\t0.63\t0.05\t1.00\t2\n",
      "22\t1.32\t0.63\t0.63\t0.05\t1.00\t2\n",
      "23\t1.33\t0.63\t0.63\t0.05\t1.00\t2\n",
      "24\t1.43\t0.63\t0.63\t0.05\t1.00\t2\n",
      "25\t1.33\t0.63\t0.63\t0.05\t1.00\t2\n",
      "26\t1.34\t0.63\t0.63\t0.05\t1.00\t2\n",
      "27\t1.34\t0.63\t0.63\t0.05\t1.00\t2\n",
      "28\t1.44\t0.63\t0.63\t0.05\t1.00\t2\n",
      "29\t1.34\t0.63\t0.63\t0.05\t1.00\t2\n",
      "30\t1.36\t0.63\t0.63\t0.05\t1.00\t2\n",
      "31\t1.35\t0.63\t0.63\t0.05\t1.00\t2\n",
      "32\t1.45\t0.63\t0.63\t0.05\t1.00\t2\n",
      "33\t1.36\t0.63\t0.63\t0.05\t1.00\t2\n",
      "34\t1.36\t0.63\t0.63\t0.05\t1.00\t2\n",
      "35\t1.47\t0.63\t0.63\t0.05\t1.00\t2\n",
      "36\t1.36\t0.63\t0.63\t0.05\t1.00\t2\n",
      "37\t1.51\t0.63\t0.63\t0.05\t1.00\t2\n",
      "38\t1.38\t0.63\t0.63\t0.05\t1.00\t2\n",
      "39\t1.38\t0.63\t0.63\t0.05\t1.00\t2\n",
      "40\t1.38\t0.63\t0.63\t0.05\t1.00\t2\n",
      "Results of 40 runs (mean,std_var,min,max):\n",
      "\t Acc: 0.630466472303207, 0.0, 0.630466472303207, 0.630466472303207\n",
      "\t F1 : 0.6296351906258454, 0.0, 0.6296351906258454, 0.6296351906258454\n",
      "\t NMI: 0.05132085644829656, 0.0, 0.05132085644829656, 0.05132085644829656\n",
      "Running time: 55.20810675621033s\n"
     ]
    }
   ],
   "source": [
    "evaluation(kmedoids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
